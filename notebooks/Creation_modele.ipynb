{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:03:03.350950Z",
     "start_time": "2019-11-26T23:03:03.345656Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge,  ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectif\n",
    "\n",
    "Je veux créer un modèle de Machine Learning à predire la consommation électrique prévue pour la semaine à venir.\n",
    "\n",
    "La consommation électrique j'ai utilisé est `Global_active_power`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:03:04.220365Z",
     "start_time": "2019-11-26T23:03:04.202939Z"
    }
   },
   "outputs": [],
   "source": [
    "day_df = pd.read_csv('../data/output/day_cleaned_household_power_consumption.csv', header=0, \n",
    "                    infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diviser un ensemble de données en ensembles train / validation\n",
    "\n",
    "Je vais utiliser les données des trois premières années pour l'entrainement du modèle et la dernière année pour l'évaluation du modèle.\n",
    "\n",
    "Je veux que les données d'un ensemble de données seront divisées en semaines. Ce sont des semaines qui commencent un dimanche et se terminent un samedi. Donc, je laisse tomber le premier jour qui est Samedi, et la dernière semaine sans Samedi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:03:04.770539Z",
     "start_time": "2019-11-26T23:03:04.763204Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_valid_diviser(values):\n",
    "    '''\n",
    "    diviser un ensemble de données en ensembles train / test par années\n",
    "    \n",
    "    Parameters:\n",
    "    -- values - un np.array avec 2 dimensions\n",
    "    '''\n",
    "    # divisées par années\n",
    "    train, valid = values[1:-328], values[-328:-6]\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:03:05.043581Z",
     "start_time": "2019-11-26T23:03:05.038567Z"
    }
   },
   "outputs": [],
   "source": [
    "train, valid = train_test_diviser(day_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, je prends `Global_active_power` qui est dans la première colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:03:05.653051Z",
     "start_time": "2019-11-26T23:03:05.649015Z"
    }
   },
   "outputs": [],
   "source": [
    "train_conso = train[:,0]\n",
    "valid_conso = valid[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# créer le modèle\n",
    "\n",
    "J'applique l'algo `Recursive Multi-Step Forecasting`. En gros, elle crée le modèle fait une prédiction pour un pas de temps, et elle prend cette prédiction comme les donées pour créer un nouveau model et faire la prochaine prédiction dans un pas de temps suivant. Ce processus est répété jusqu'à ce que le nombre d'étapes souhaité ait été prévu.\n",
    "\n",
    "Ici, un pas de temps est une semaine. Le modèle est un modèle supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T21:08:57.925704Z",
     "start_time": "2019-11-26T21:08:57.918321Z"
    }
   },
   "source": [
    "## transformer les données\n",
    "\n",
    "Tout d'abord, il faut transformer les données dans deux parties, `feature` et `target`, pour entrainer le modèle. Dans Machine Learning, `feature` est les données pour entrainer le modèle, `target` est le données qu'on veut prédire.\n",
    "\n",
    "Dans ce projet, `feature` est les consommations dans un pas de temps, `target` est la consommation dans le jour suivant. Par exemple, si je prends les consommations de Dimanche à Samedi comme `feature`, alors le prochain Dimanche est `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:03:11.855073Z",
     "start_time": "2019-11-26T23:03:11.847621Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_target_split(data, stride = 7):\n",
    "    '''\n",
    "    transformer les donnéés dans 2 parties\n",
    "    \n",
    "    Parameters:\n",
    "    -- data - la conso, 1 dimension\n",
    "    -- slide - nombre de jour choisi pour créer feature. Une samaine (7) par defaut\n",
    "    '''\n",
    "    feature = []\n",
    "    target = []\n",
    "    \n",
    "    i_start = 0\n",
    "    for i in range(len(data)):\n",
    "        i_end = i_start + stride\n",
    "        if i_end < len(data):\n",
    "            feature.append(data[i_start:i_end])\n",
    "            target.append(data[i_end])\n",
    "            i_start += 1\n",
    "    \n",
    "    return np.array(feature), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:08:01.852979Z",
     "start_time": "2019-11-26T23:08:01.841339Z"
    }
   },
   "outputs": [],
   "source": [
    "train_feature, train_target = feature_target_split(train_conso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construire le modèle pour un pas du temps\n",
    "\n",
    "Dans cette partie, je simplement ajoute 2 couches avant le modèle de Machine Learning. Un couche est pour standardiser les données. La sortie est central réduit. La couche suivant est pour normaliser les données. Elle met les données entre 0 et 1.\n",
    "\n",
    "Les modèles de machine learning que je choisis sont `Regression Lineair` et celles avec la penalité sur le nombre de `feature`, comme `Ridge`, `Lasso` et `ElasticNet`. Elles sont simple et interprétable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:17:01.717527Z",
     "start_time": "2019-11-26T23:17:01.710331Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_step_model(model):\n",
    "    '''\n",
    "    ajouter un couche de standardisation et un couche de normalisation avant le modèle de Machine Learning\n",
    "    '''\n",
    "    steps = []\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    steps.append(('normalize', MinMaxScaler()))\n",
    "    steps.append(('model', model))\n",
    "    \n",
    "    step_model = Pipeline(steps=steps)\n",
    "    return step_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forcast\n",
    "\n",
    "J'utilse le modèle que j'ai créé pour réaliser l'algo `Recursive Multi-Step Forecasting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:17:02.274294Z",
     "start_time": "2019-11-26T23:17:02.259625Z"
    }
   },
   "outputs": [],
   "source": [
    "def recursive_multi_step_forecasting(model, feature):\n",
    "    '''\n",
    "    réaliser l'algo Recursive Multi-Step Forecasting\n",
    "    \n",
    "    Parameters:\n",
    "    -- model - le modèle d'un pas du temps\n",
    "    -- feature - les features qui creéent le modèle d'un pas du temps\n",
    "    '''\n",
    "    pred_sequence = []\n",
    "    history = list(feature)\n",
    "    stride = len(feature)\n",
    "    \n",
    "    for j in range(stride):\n",
    "        X = np.array(history[-stride:]).reshape(1, stride)\n",
    "        pred = model.predict(X)[0]\n",
    "        pred_sequence.append(pred)\n",
    "        # ajouter la prediction dans les données entrées\n",
    "        history.append(pred)\n",
    "    return np.array(pred_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## créer le modèle final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:28:55.449534Z",
     "start_time": "2019-11-26T23:28:55.442569Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_prediction(model, train, valid, stride=7):\n",
    "    history = list(train)\n",
    "    pred = []\n",
    "    \n",
    "    for i in range(0,len(valid),7):\n",
    "        train_x, train_y = feature_target_split(history)\n",
    "        step_model = create_step_model(model)\n",
    "        step_model.fit(train_x, train_y)\n",
    "        pred_sequence = recursive_multi_step_forecasting(step_model, train_feature[-1, :])\n",
    "        \n",
    "        pred.append(pred_sequence)\n",
    "        # get real observation and add to history for predicting the next day\n",
    "        history.append(valid[i])\n",
    "    \n",
    "    return np.array(pred).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:28:56.873992Z",
     "start_time": "2019-11-26T23:28:56.624138Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = model_prediction(LinearRegression(), train_conso, valid_conso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "502px",
    "left": "1566px",
    "right": "20px",
    "top": "120px",
    "width": "339px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
